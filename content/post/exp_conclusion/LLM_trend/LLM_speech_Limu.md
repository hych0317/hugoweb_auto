+++
title = 'LLM趋势及个人生涯分享--李沐'
date = 2024-08-24T21:01:10+08:00
draft = false
description = "本文为对李沐老师2024.8.23于上交报告的总结、体会。报告原文保存在本文相同路径下。"
categories = ['conclusion']
+++

## 第一部分：LLM
继上一次的深度学习浪潮，现在兴起的是语言模型浪潮。

语言模型可以分为三块：算力、数据和算法。(丹炉、药材、炼丹术)

### 算力

#### 算力的发展趋势
长期来看，算力的成本将持续降低，大模型训练成本也会不断下降，所以大模型本身也不是一个能保值的东西，价值会随着时间降低，也某种意义上受摩尔定律的影响(训练会两倍两倍地变便宜，今天训练一个模型，一年之后它的价值会减半)。

**大模型不是特别有性价比的东西。你要想清楚，从长期来看，你的模型能带来什么价值，让你能够保值。**

100B 到 500B 会是未来主流的一个大势。你可以做更大，但是它很多时候是用 MoE 做的，它的有效大小（每次激活的大小）可能也就是 500B 的样子。

PS：对于模型开发者来说，要想在模型的参数量、预训练上想取得突破是不明智的，头部企业的突破速度不是小团队可以想象的。更应该关注模型的后训练、应用部署。
#### 算力的瓶颈
通信带宽：分布式训练要求多卡间的通信延迟足够小。由于供电、散热的问题，芯片间需要保持一定距离，导致了通信延迟。  
即使是使用光纤以光速传输，一米距离传输带来的几纳秒延迟对性能影响也很大。

内存：大模型训练需要大量的内存，目前最大的单个内存芯片可以达到192GB。  
内存占面积大，一个芯片划一块给算力，划一块给内存之后就放不下什么东西了。这会严重限制模型大小。  
(在这一块，虽然英伟达是领先者，但其实英伟达是不如 AMD 的，甚至不如 Google 的 TPU)

### 数据
当前数据**质量**的提升比数量提升更重要。

数据决定了模型的上限，算法决定了模型的下限。  
就目前来说，我们离 AGI 还很远， AGI 能够做自主的学习，我们目前的模型就是填鸭式状态。  
Claude团队花了很大的力气来做数据，在数据上用了很多年。所以，想让模型在某一个方面做得特别好，需要先把相关数据准备好。大家还是用了 70-80% 时间在数据上。

数据质量的提升还来自于：
1. 标注数据：语言模型的训练数据需要大量的标注数据，比如训练集、验证集、测试集。
2. 领域数据：语言模型的训练数据需要包含领域相关的文本，比如新闻、科技、医疗等。
3. 多样性：语言模型的训练数据需要包含各种语言、方言、口音等多样性的文本。

### 趋势
End-to-end和多模态是当前大模型的趋势。  

目前语言模型已经达到了较高的水平，大约在 80 到 85 分之间。音频模型在可接受的水平，处于能用阶段，大约在 70-80 分之间。但在视频生成方面，尤其是生成具有特定功能的视频尚显不足，整体水平大约在 50 分左右。  

#### 技术层面

##### 多模态技术
多模态技术的发展趋势在于整合不同类型的模态信息。  
由于文本是信息密度最高的，也是最容易获得的。  
一是可以借助强大的文本模型进行泛化。二是可以通过文本来定制和控制其他模态的输出，比如用简单的文本指令控制图片、视频和声音的生成。

##### 预训练与后训练
预训练是用大量的文本数据训练一个通用语言模型，后训练是用这个通用语言模型来训练特定任务的模型。

**预训练是工程问题，后训练才是技术问题**  
在预训练方面，现在已经变成一个因为大而导致很多工程问题的困难，这其实还是算法上探索不够，得清楚如何改进算法。  
对于后训练，**高质量的数据和改进的算法**能够极大地提升模型效果。高质量的数据一定是结构化的，并且与应用场景高度相关，以保证数据的多样性和实用性。

##### 垂直模型也需要通用维度
为什么要做垂直模型呢？因为通用模型的问题还是一个指数问题，你要实现的任务，通用模型不一定能完成。  
通用模型是通用维度，需要各个方面都有提升，如果刚好满足你的要求，需要指数级的数据，并且模型会变得很大。

**但是**就算是一个很垂直领域的模型，它的通用能力也是不能差的。比如说你要在某一个学科里面拿第一，你别的科目也不能差到哪里去。

##### 模型评估
自然语言很难评价其正确性、逻辑性和风格。通常我们不想让人来评估，因为比较昂贵，但使用模型评估会带来偏差。  
有一个好的评估可以解决 50% 的问题。因为一旦评估解决了，那你就能够进行优化。第二评估解决了，表示你拥有了一些数据。

#### 应用层面
##### 人机交互
人机交互的方式可能会发生改变。以往人机交互都是通过键鼠和屏幕完成的，未来的语音控制系统将能够处理更加复杂和具体的任务。  
手机的 killer APP 是什么吗？短视频。语言模型的killer APP是什么？这个还是未知。

##### 对人类的替代
数据越多的领域，就越能被自动化。  
当前大模型在简单的文科任务上已经能很好地代替人类。因为文科任务是最能简单快速采集大量数据的。在简单理科任务和复杂文科任务上能力正在突破。  
而当前想要替代蓝领，还非常遥远。工厂需要投放大量传感器，做好数字化基础设施建设，数据收集和整理方案成熟起来，才有大模型落地的希望。而这一切当前看来还很难，但一旦实现就会是重大变革。

## 第二部分：职业规划建议

### 几种身份的区别
**目标和动机的差异**
![差别](post/exp_conclution/LLM_trend/diff.png)
大厂的目标是升职加薪，PhD的目标就是博士毕业，创业的目标就是套现退出

**优缺点分析**
![打工人](post/exp_conclution/LLM_trend/dgr.png)
晚上不用做噩梦，但逐渐成为螺丝钉。  
好处是，可以在一个相对简单的环境里学习各种从业知识、有相对稳定的收入和空余时间；坏处就是停留在打工人或者职业经理人的思维。

![PhD](post/exp_conclution/LLM_trend/phd.png)
好处是，在几年的时间里可以专心探索某一个领域；  
坏处是，很少有实验室能参与大项目的研发，并且需要有很强的自我驱动力。要真的热爱研究，不然坚持不下去，你会觉得研究这个东西到底有什么意义，写这篇论文要干嘛。  
其实，你可以这样想：我写这篇文章就是为了练习写作，等到更厉害、更大的成果做出来后，写作不能给我拉后腿。你要有一个更远大的目标，是真的热爱它。  
PS：读不了一点

![创业](post/exp_conclution/LLM_trend/startup.png)

### 驱动力的来源
![动机](post/exp_conclution/LLM_trend/motivation.png)
欲望是越底层越好，名、利、权，都是底层的欲望。恐惧是可以让你抑郁的恐惧，也是让你感受到生死的恐惧。  

你需要把欲望和恐惧转变成积极向上的动机，你的动机一定是正确的，符合价值观的，因为逃避、放纵满足不了欲望，也缓解不了恐惧，唯一克服它的办法是，把它变成一个积极向上、符合社会价值的一个动机。  

![动机差异](post/exp_conclution/LLM_trend/motidiff.png)
有了动机之后就得想，我要解决什么问题，你的问题可能就是你的动机本身。  

举例来说，语言模型为什么能运作？没人知道，这是一个很有学术价值的东西。语言模型能不能孵化出新的应用？这是商业价值上的问题。实在不行的话，也可以思考语言模型在某个产品上如何落地。  

**一个提升自我的方法**
![方法](post/exp_conclution/LLM_trend/improve.png)
为什么目标没达成？  

可能是因为懒，那么你得直面懒的问题。我怎么能让自己勤奋一点？找一个学习伙伴，每天在图书馆待着，要大家相互监督等。  
还有可能是因为蠢，这就有两种解决方案。一种是换一个方向，去擅长的领域；一种是既然绕不开，那就花别人两倍的时间。  
无论是因为懒还是蠢，你都得对自己狠，最后拼的就是你对自己有多狠。  

你要形成一个习惯，定个闹钟，每周一晚上花 30 分钟对自己进行总结，每个季度要总结，翻看之前你的写的周记，看看这个季度的目标是否完成，下个季度要做什么。

选择比努力更重要，但选择的前提是搞清楚你的目标是什么。